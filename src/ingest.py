"""
Script d'indexation des donnÃ©es du portfolio dans Upstash Vector.

Ce module gÃ¨re le pipeline d'ingestion des fichiers Markdown du portfolio :
    1. Chargement des fichiers .md depuis le dossier data/
    2. DÃ©coupage intelligent par sections (titres # et ##)
    3. Indexation dans Upstash Vector pour la recherche hybride

Usage:
    python ingest.py

Note:
    Ce script doit Ãªtre exÃ©cutÃ© une seule fois pour charger les donnÃ©es initiales,
    ou Ã  chaque mise Ã  jour du contenu du portfolio.
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Optional

from dotenv import load_dotenv
from upstash_vector import Index

# Chargement des variables d'environnement depuis .env
load_dotenv()


def load_markdown_file(file_path: Path) -> str:
    """
    Charge le contenu d'un fichier Markdown.

    Args:
        file_path: Chemin absolu ou relatif vers le fichier Markdown Ã  lire.

    Returns:
        Contenu brut du fichier sous forme de chaÃ®ne de caractÃ¨res.
        Retourne une chaÃ®ne vide en cas d'erreur de lecture.

    Raises:
        Aucune exception levÃ©e directement ; les erreurs sont capturÃ©es
        et loguÃ©es dans la console.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Erreur lors de la lecture de {file_path}: {e}")
        return ""


def chunk_markdown_by_headings(content: str, source_file: str) -> List[Dict[str, str]]:
    """
    DÃ©coupe un document Markdown en chunks basÃ©s sur les titres.

    Chaque section dÃ©limitÃ©e par un titre de niveau 1 (#) ou 2 (##) devient
    un chunk indÃ©pendant avec ses mÃ©tadonnÃ©es associÃ©es.

    Args:
        content: Contenu brut du fichier Markdown Ã  dÃ©couper.
        source_file: Nom du fichier source (utilisÃ© dans les mÃ©tadonnÃ©es).

    Returns:
        Liste de dictionnaires, chacun contenant :
            - "text": Le contenu textuel du chunk (titre + corps).
            - "metadata": Dict avec "source" (nom fichier) et "title" (titre section).

    Example:
        >>> chunks = chunk_markdown_by_headings("# Titre\\nContenu", "cv.md")
        >>> chunks[0]["metadata"]["title"]
        'Titre'
    """
    chunks: List[Dict[str, str]] = []

    # Regex pour sÃ©parer le contenu par titres H1/H2 tout en conservant les dÃ©limiteurs
    sections = re.split(r'(^#{1,2}\s+.+$)', content, flags=re.MULTILINE)

    current_title: str = ""
    current_content: str = ""

    for section in sections:
        section = section.strip()
        if not section:
            continue

        # DÃ©tection d'un titre Markdown (commence par # ou ##)
        if re.match(r'^#{1,2}\s+', section):
            # Sauvegarder le chunk prÃ©cÃ©dent avant de passer au suivant
            if current_content:
                chunks.append({
                    "text": f"{current_title}\n\n{current_content}".strip(),
                    "metadata": {
                        "source": source_file,
                        "title": current_title.strip('#').strip()
                    }
                })

            current_title = section
            current_content = ""
        else:
            # Accumulation du contenu sous le titre courant
            current_content += section + "\n"

    # Ajout du dernier chunk (aprÃ¨s la derniÃ¨re section)
    if current_content:
        chunks.append({
            "text": f"{current_title}\n\n{current_content}".strip(),
            "metadata": {
                "source": source_file,
                "title": current_title.strip('#').strip() if current_title else "Introduction"
            }
        })

    return chunks


def index_data_to_upstash(chunks: List[Dict[str, str]], index: Index) -> int:
    """
    Indexe les chunks dans Upstash Vector via upsert.

    Utilise le mode Hybrid d'Upstash qui gÃ©nÃ¨re automatiquement les embeddings
    (dense via BAAI/bge-m3 + sparse via BM25).

    Args:
        chunks: Liste des chunks Ã  indexer (chacun avec "text" et "metadata").
        index: Instance de l'index Upstash Vector initialisÃ©e.

    Returns:
        Nombre de chunks indexÃ©s avec succÃ¨s.

    Raises:
        Aucune exception levÃ©e directement ; les erreurs sont capturÃ©es
        et loguÃ©es dans la console pour chaque chunk.
    """
    indexed_count: int = 0

    for i, chunk in enumerate(chunks):
        try:
            # Upsert : insertion ou mise Ã  jour si l'ID existe dÃ©jÃ 
            index.upsert(
                vectors=[{
                    "id": f"chunk_{i}_{chunk['metadata']['source']}",
                    "data": chunk["text"],  # Texte brut pour embedding automatique
                    "metadata": chunk["metadata"]
                }]
            )
            indexed_count += 1
            print(f"Chunk {i+1}/{len(chunks)} indexÃ©: {chunk['metadata']['title'][:50]}...")
        except Exception as e:
            print(f"Erreur lors de l'indexation du chunk {i}: {e}")

    return indexed_count


def main() -> None:
    """
    Fonction principale orchestrant le pipeline d'indexation.

    Ã‰tapes exÃ©cutÃ©es :
        1. Validation des variables d'environnement Upstash
        2. Connexion Ã  l'index Upstash Vector
        3. Lecture de tous les fichiers .md du dossier data/
        4. DÃ©coupage en chunks par sections Markdown
        5. Indexation dans Upstash Vector
        6. Affichage des statistiques finales

    Returns:
        None

    Raises:
        Aucune exception levÃ©e ; le script s'arrÃªte proprement en cas d'erreur
        de configuration ou de connexion.
    """
    print("ğŸš€ DÃ©marrage de l'indexation du portfolio...")

    # --- Ã‰tape 1 : Validation des credentials Upstash ---
    upstash_url: Optional[str] = os.getenv("UPSTASH_VECTOR_REST_URL")
    upstash_token: Optional[str] = os.getenv("UPSTASH_VECTOR_REST_TOKEN")

    if not upstash_url or not upstash_token:
        print("âŒ Erreur: Variables d'environnement UPSTASH_VECTOR_REST_URL et/ou UPSTASH_VECTOR_REST_TOKEN manquantes.")
        print("ğŸ’¡ Assurez-vous d'avoir crÃ©Ã© un fichier .env Ã  partir de .env.example")
        return

    # --- Ã‰tape 2 : Connexion Ã  Upstash Vector ---
    try:
        index = Index(url=upstash_url, token=upstash_token)
        print("âœ… Connexion Ã  Upstash Vector rÃ©ussie")
    except Exception as e:
        print(f"âŒ Erreur de connexion Ã  Upstash Vector: {e}")
        return

    # --- Ã‰tape 3 : DÃ©couverte des fichiers Markdown ---
    data_dir = Path("data")
    if not data_dir.exists():
        print(f"âŒ Erreur: Le dossier {data_dir} n'existe pas")
        return

    markdown_files: List[Path] = list(data_dir.glob("*.md"))
    if not markdown_files:
        print(f"âŒ Aucun fichier .md trouvÃ© dans {data_dir}")
        return

    print(f"ğŸ“ {len(markdown_files)} fichiers Markdown trouvÃ©s")

    # --- Ã‰tape 4 : Traitement et chunking ---
    all_chunks: List[Dict[str, str]] = []
    for md_file in sorted(markdown_files):
        print(f"\nğŸ“„ Traitement de {md_file.name}...")
        content = load_markdown_file(md_file)

        if content:
            chunks = chunk_markdown_by_headings(content, md_file.name)
            all_chunks.extend(chunks)
            print(f"   âœ… {len(chunks)} chunks crÃ©Ã©s")

    print(f"\nğŸ“Š Total: {len(all_chunks)} chunks Ã  indexer")

    # --- Ã‰tape 5 : Indexation dans Upstash ---
    print("\nğŸ”„ Indexation en cours...")
    indexed = index_data_to_upstash(all_chunks, index)

    print(f"\nğŸ‰ Indexation terminÃ©e: {indexed}/{len(all_chunks)} chunks indexÃ©s avec succÃ¨s")

    # --- Ã‰tape 6 : VÃ©rification et statistiques ---
    try:
        info = index.info()
        print(f"ğŸ“ˆ Statistiques de l'index:")
        print(f"   - Dimension: {info.dimension}")
        print(f"   - Total vecteurs: {info.vector_count}")
    except Exception as e:
        print(f"âš ï¸ Impossible de rÃ©cupÃ©rer les statistiques: {e}")


if __name__ == "__main__":
    main()
